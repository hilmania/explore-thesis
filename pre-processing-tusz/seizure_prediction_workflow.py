#!/usr/bin/env python3
"""
TUSZ Seizure Prediction Workflow Example
========================================

Contoh lengkap workflow untuk mempersiapkan dataset TUSZ
untuk prediksi seizure dengan fase pre-ictal 20 menit.

Workflow:
1. Select suitable files (durasi â‰¥20 min, ada seizure)
2. Extract pre-ictal segments (20 min sebelum seizure)
3. Extract interictal segments (periode tanpa seizure)
4. Generate balanced dataset untuk training

Author: Assistant
Date: July 2025
"""

import json
import os
from pathlib import Path
from collections import Counter
import argparse

def demo_seizure_prediction_workflow():
    """Demonstrasi workflow lengkap untuk seizure prediction"""

    print("ğŸ§  TUSZ SEIZURE PREDICTION WORKFLOW")
    print("=" * 60)

    print("\nğŸ“‹ STEP 1: DATASET SELECTION")
    print("-" * 30)
    print("Kriteria untuk prediksi seizure:")
    print("âœ… Durasi recording â‰¥ 20 menit")
    print("âœ… Memiliki seizure events (bukan hanya background)")
    print("âœ… Ada periode pre-ictal minimal 20 menit sebelum seizure")
    print("âœ… Kualitas signal yang baik")

    print("\nContoh command:")
    print("python seizure_prediction_selector.py \\")
    print("    --dataset_path . \\")
    print("    --min_duration 20 \\")
    print("    --preictal_duration 20 \\")
    print("    --output_dir ./prediction_dataset \\")
    print("    --quality_threshold 70 \\")
    print("    --verbose")

    print("\nğŸ“Š EXPECTED RESULTS:")
    print("Dari ~4,664 files, diperkirakan:")
    print("   â€¢ ~500-800 files suitable (10-15%)")
    print("   â€¢ ~300-500 unique patients")
    print("   â€¢ ~1,000-2,000 seizure events")
    print("   â€¢ ~200-400 jam total data")

    print("\nğŸ“‹ STEP 2: PRE-ICTAL EXTRACTION")
    print("-" * 30)
    print("Extract segmen EEG untuk training:")
    print("âš¡ Pre-ictal: 20 menit sebelum onset seizure")
    print("ğŸ”„ Interictal: 20 menit dari periode tanpa seizure")
    print("ğŸ“Š Balanced dataset: 1:1 ratio pre-ictal:interictal")

    print("\nContoh command:")
    print("python preictal_processor.py \\")
    print("    --prediction_dataset ./prediction_dataset/prediction_dataset.json \\")
    print("    --output_dir ./preictal_data \\")
    print("    --preictal_duration 20 \\")
    print("    --interictal_duration 20 \\")
    print("    --sampling_rate 250 \\")
    print("    --verbose")

    print("\nğŸ“Š EXPECTED OUTPUT:")
    print("   â€¢ preictal_data.npy: (N, channels, samples)")
    print("   â€¢ interictal_data.npy: (N, channels, samples)")
    print("   â€¢ Segment shape: (22 channels, 300,000 samples) @ 250Hz")
    print("   â€¢ Total segments: 1,000-2,000 per class")

    print("\nğŸ“‹ STEP 3: DATA ANALYSIS")
    print("-" * 25)
    print("Analisis dataset yang dihasilkan:")

    # Simulasi analisis berdasarkan data yang sudah ada
    print("\nğŸ” DATASET CHARACTERISTICS:")
    print("ğŸ“Š Total Files Analyzed: 4,664")
    print("âœ… Suitable Files: ~800 (17.2%)")
    print("â±ï¸  Average Duration: 32.5 minutes")
    print("ğŸ§  Seizure Types Found:")

    # Berdasarkan label distribution dari analysis report
    seizure_distribution = {
        'cpsz': 3002,  # Complex Partial Seizure
        'fnsz': 12889, # Focal Non-specific Seizure
        'gnsz': 7570,  # Generalized Non-specific Seizure
        'tcsz': 633,   # Tonic-Clonic Seizure
        'absz': 1099,  # Absence Seizure
        'mysz': 44,    # Myoclonic Seizure
        'tnsz': 380,   # Tonic Seizure
        'spsz': 942    # Simple Partial Seizure
    }

    total_seizures = sum(seizure_distribution.values())

    for seizure_type, count in sorted(seizure_distribution.items(),
                                     key=lambda x: x[1], reverse=True):
        percentage = (count / total_seizures) * 100
        print(f"   â€¢ {seizure_type}: {count:,} events ({percentage:.1f}%)")

    print(f"\nğŸ“ˆ PREDICTION DATASET ESTIMATES:")
    suitable_seizures = int(total_seizures * 0.3)  # Estimate 30% have enough pre-ictal
    print(f"   â€¢ Pre-ictal segments: ~{suitable_seizures:,}")
    print(f"   â€¢ Interictal segments: ~{suitable_seizures:,}")
    print(f"   â€¢ Total training samples: ~{suitable_seizures*2:,}")
    print(f"   â€¢ Data size: ~{suitable_seizures*2*22*300000*4/1e9:.1f} GB")

    print("\nğŸ“‹ STEP 4: MODEL TRAINING PREPARATION")
    print("-" * 35)
    print("Dataset siap untuk training dengan:")
    print("ğŸ“Š Features: 22-channel EEG, 20-minute windows")
    print("ğŸ¯ Target: Binary classification (pre-ictal vs interictal)")
    print("ğŸ”„ Cross-validation: By patient (tidak ada data leakage)")
    print("âš–ï¸  Class balance: 1:1 ratio")

    print("\nğŸš€ RECOMMENDED NEXT STEPS")
    print("-" * 25)
    print("1. ğŸ” Feature Engineering:")
    print("   â€¢ Spectral features (power bands)")
    print("   â€¢ Time-domain features (statistics)")
    print("   â€¢ Connectivity features (coherence)")
    print("   â€¢ Entropy measures")

    print("\n2. ğŸ¤– Model Development:")
    print("   â€¢ Deep learning: CNN, LSTM, Transformer")
    print("   â€¢ Traditional ML: SVM, Random Forest")
    print("   â€¢ Ensemble methods")
    print("   â€¢ Online learning approaches")

    print("\n3. ğŸ“Š Evaluation Strategy:")
    print("   â€¢ Patient-independent validation")
    print("   â€¢ Temporal validation (chronological)")
    print("   â€¢ Sensitivity/Specificity analysis")
    print("   â€¢ False positive rate per hour")

    print("\nğŸ’¡ PRACTICAL CONSIDERATIONS")
    print("-" * 28)
    print("âš ï¸  Challenges:")
    print("   â€¢ Class imbalance in real-world scenarios")
    print("   â€¢ Patient-specific seizure patterns")
    print("   â€¢ Real-time processing requirements")
    print("   â€¢ False positive tolerance")

    print("\nâœ… Solutions:")
    print("   â€¢ Patient-specific model adaptation")
    print("   â€¢ Multi-stage prediction pipeline")
    print("   â€¢ Continuous learning approaches")
    print("   â€¢ Confidence threshold optimization")

    print("\nğŸ“š EXAMPLE CODE SNIPPETS")
    print("-" * 25)

    print("\n# Load processed data")
    print("from preictal_processor import load_processed_data")
    print("data = load_processed_data('./preictal_data')")
    print("preictal_eeg = data['preictal']['data']")
    print("interictal_eeg = data['interictal']['data']")

    print("\n# Create labels")
    print("import numpy as np")
    print("n_preictal = preictal_eeg.shape[0]")
    print("n_interictal = interictal_eeg.shape[0]")
    print("labels = np.concatenate([")
    print("    np.ones(n_preictal),      # Pre-ictal = 1")
    print("    np.zeros(n_interictal)    # Interictal = 0")
    print("])")

    print("\n# Combine data")
    print("X = np.concatenate([preictal_eeg, interictal_eeg])")
    print("y = labels")
    print("print(f'Dataset shape: {X.shape}')")
    print("print(f'Labels shape: {y.shape}')")

    print("\n# Split by patient")
    print("from sklearn.model_selection import GroupKFold")
    print("patient_ids = [info['patient_id'] for info in data['preictal']['info']['segments']]")
    print("patient_ids.extend([info['patient_id'] for info in data['interictal']['info']['segments']])")
    print("gkf = GroupKFold(n_splits=5)")
    print("for train_idx, val_idx in gkf.split(X, y, patient_ids):")
    print("    X_train, X_val = X[train_idx], X[val_idx]")
    print("    y_train, y_val = y[train_idx], y[val_idx]")
    print("    # Train model...")

    print(f"\nğŸ¯ SUMMARY")
    print("-" * 15)
    print("Tools telah dibuat untuk complete workflow:")
    print("âœ… seizure_prediction_selector.py - Select suitable files")
    print("âœ… preictal_processor.py - Extract pre-ictal segments")
    print("âœ… Automated train/val splits by patient")
    print("âœ… Quality scoring dan filtering")
    print("âœ… Comprehensive metadata tracking")

    print(f"\nDataset TUSZ siap untuk seizure prediction research!")

def analyze_existing_results(prediction_dataset_path):
    """Analyze existing prediction dataset results"""

    if not os.path.exists(prediction_dataset_path):
        print(f"âŒ Prediction dataset not found: {prediction_dataset_path}")
        return

    print(f"\nğŸ“Š ANALYZING EXISTING RESULTS")
    print("-" * 35)

    try:
        with open(prediction_dataset_path) as f:
            dataset = json.load(f)

        files = dataset.get('files', [])
        print(f"ğŸ“„ Selected Files: {len(files)}")

        if files:
            # Analyze duration distribution
            durations = [f['total_duration']/60 for f in files]
            avg_duration = sum(durations) / len(durations)
            print(f"â±ï¸  Average Duration: {avg_duration:.1f} minutes")

            # Analyze seizure types
            all_seizure_types = []
            total_seizures = 0

            for f in files:
                events = f.get('suitable_events', [])
                total_seizures += len(events)
                for event in events:
                    all_seizure_types.append(event['label'])

            seizure_counts = Counter(all_seizure_types)
            print(f"ğŸ§  Total Seizures: {total_seizures}")
            print(f"ğŸ·ï¸  Seizure Types:")

            for seizure_type, count in seizure_counts.most_common():
                percentage = (count / total_seizures) * 100
                print(f"   â€¢ {seizure_type}: {count} ({percentage:.1f}%)")

            # Analyze patient distribution
            patients = set()
            for f in files:
                path_parts = Path(f['file_path']).parts
                if len(path_parts) >= 4:
                    patients.add(path_parts[-4])

            print(f"ğŸ‘¥ Unique Patients: {len(patients)}")

            # Quality scores
            quality_scores = [f.get('quality_score', 0) for f in files]
            avg_quality = sum(quality_scores) / len(quality_scores)
            print(f"ğŸ† Average Quality: {avg_quality:.1f}")

            print(f"\nâœ… Dataset ready for pre-ictal processing!")

    except Exception as e:
        print(f"âŒ Error analyzing results: {e}")

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description='TUSZ Seizure Prediction Workflow Demo')
    parser.add_argument('--analyze_results',
                       help='Path to existing prediction_dataset.json to analyze')

    args = parser.parse_args()

    if args.analyze_results:
        analyze_existing_results(args.analyze_results)
    else:
        demo_seizure_prediction_workflow()

if __name__ == "__main__":
    main()
